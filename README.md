# Rowdy Datathon 2023 - Congressional Resource Allocation Analysis

## Introduction

Welcome to our GitHub repository for the Rowdy Datathon 2023 project. This repository contains the code and resources for our project, which focuses on analyzing and recommending resource allocation strategies to increase educational attainment in congressional districts.

## Problem Description

In the context of Rowdy Datathon 2023, our objectives were as follows:

1. Determine the socioeconomic factors influencing educational attainment.
2. Recommend resource allocation strategies based on our analysis.
3. Conduct the analysis for Texas and make comparisons with other states.

Our project includes an executive report and technical materials that support our analysis.

## Data Description

For this project, we exclusively utilized the following datasets from the "2017-18 Civil Rights Data Collection (CRDC)" folder:

- [ID 22 SCH - Title I Status.csv](data/2017-18 Civil Rights Data Collection (CRDC)/ID 22 SCH - Title I Status.csv)
- [LEA Characteristics.csv](data/2017-18 Civil Rights Data Collection (CRDC)/LEA Characteristics.csv)
- [Enrollment.csv](data/2017-18 Civil Rights Data Collection (CRDC)/Enrollment.csv)

## Project Structure

Our project is organized as follows:

- **`data/`**: Contains the selected raw data files from the "2017-18 Civil Rights Data Collection (CRDC)" folder.
- **`scripts/`**: Includes Python scripts for data preprocessing, database interaction, and graph generation.
- **`sql/`**: Contains custom SQL schemas for generating and organizing new data.
- **`reports/`**: Holds the executive report and technical appendix.
- **`README.md`: The main project README file (this document).

## Instructions

To replicate our analysis or use our code, follow these steps:

1. Download the required datasets listed above from the "2017-18 Civil Rights Data Collection (CRDC)" folder and place them in the `data/` directory.
2. Run the Python scripts in the `scripts/` directory to sanitize the data, interact with the database, and generate graphs.
3. Use the custom SQL schemas in the `sql/` directory to organize the data and perform queries.
4. Refer to the reports in the `reports/` directory for detailed findings and recommendations.

## Contributors

- [Brandon Hawkins](https://github.com/BhawksGit)
- [Carly Munoz](https://github.com/carlyam02)
- [Alex Rheney](https://github.com/JaR448)
- [Jacob Quintero](https://github.com/Jquintero08)
